{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一个简单的cv2读取视频流\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read() #读取，ret代表着读取frame的一些参数\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame) # 展示图像\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #按q退出\n",
    "        break\n",
    "cap.release() #清楚\n",
    "cv2.destroyAllWindows() #关掉window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结合上次我们的dlib\n",
    "detector = dlib.get_frontal_face_detector() #跟opencv的haar作用一样，用来检测人脸\n",
    "predictor = dlib.shape_predictor(\"first/shape_predictor_68_face_landmarks.dat\") \n",
    "def cal_eye_dist(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    if len(faces) < 1:\n",
    "        return 0\n",
    "    landmarks = predictor(image=gray, box=faces[0]) #传入模型得到结果\n",
    "    left_one = cal_e_dist(landmarks.part(37).x, landmarks.part(41).x,\n",
    "                         landmarks.part(37).y, landmarks.part(41).y)/img.shape[0]\n",
    "    left_two = cal_e_dist(landmarks.part(38).x, landmarks.part(40).x,\n",
    "                         landmarks.part(38).y, landmarks.part(40).y)/img.shape[0]\n",
    "    right_one = cal_e_dist(landmarks.part(43).x, landmarks.part(47).x,\n",
    "                         landmarks.part(43).y, landmarks.part(47).y)/img.shape[0]\n",
    "    right_two = cal_e_dist(landmarks.part(44).x, landmarks.part(46).x,\n",
    "                         landmarks.part(44).y, landmarks.part(46).y)/img.shape[0]\n",
    "    return round(left_one,4), round(left_two,4), round(right_one,4), round(right_two,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_e_dist(x1, x2, y1, y2):\n",
    "    return np.sqrt((x1 - x2)**2 + (y1 - y2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行下面代码的时候应该会出现一个小窗口实时显示摄像头数据，摄像头上的数字是函数返回的四个值（每一个frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结合dlib\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read() #读取，ret代表着读取frame的一些参数\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    dst = cal_eye_dist(frame)\n",
    "    frame = cv2.putText(frame,str(dst),(10,200), font, 1,(255,255,255),1)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #按q退出\n",
    "        break\n",
    "cap.release() #清楚\n",
    "cv2.destroyAllWindows() #关掉window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在我们尝试复杂点\n",
    "# 前面3s帧用来设立基准线\n",
    "# fps 手动设置为10\n",
    "frame_rate = 10\n",
    "prev = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "count = 0\n",
    "baseline = [] #创建数组储存返回数据\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read() #读取，ret代表着读取frame的一些参数\n",
    "    time_elapsed = time.time() - prev #时间差\n",
    "    #print(time_elapsed)\n",
    "    if count <= 30: #3s前用来设置baseline\n",
    "        if time_elapsed > 1./frame_rate: #时间差大于我们设置好的1/fps时执行操作\n",
    "            count += 1\n",
    "            dst = cal_eye_dist(frame)\n",
    "            #print(np.mean(dst))\n",
    "            baseline.append(np.mean(dst))\n",
    "            frame_now = cv2.putText(frame,'Do not blink! Setting the baseline',(10,200), font, 1,(255,255,255),1)\n",
    "            #print(frame_b)\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('frame', frame_now)\n",
    "            cv2.waitKey(1) \n",
    "            prev = time.time()\n",
    "        continue\n",
    "    thre = np.mean(baseline) * 0.6        # using 0.6 mean as threshold. \n",
    "    if time_elapsed > 1./frame_rate: #时间差大于我们设置好的1/fps时执行操作\n",
    "        dst = cal_eye_dist(frame)\n",
    "        #print(thre, dst)\n",
    "        if np.mean(dst) < thre:\n",
    "            frame_now = cv2.putText(frame,'Warning! Tired',(10,200), font, 1,(255,255,255),1)\n",
    "        else:\n",
    "            frame_now = cv2.putText(frame,'Nothing Happened',(10,200), font, 1,(255,255,255),1)\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', frame_now)\n",
    "        prev = time.time()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #按q退出\n",
    "        break\n",
    "cap.release() #清楚\n",
    "cv2.destroyAllWindows() #关掉window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
